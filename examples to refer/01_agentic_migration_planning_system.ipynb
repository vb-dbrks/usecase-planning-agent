{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agentic Migration Planning System\n",
        "\n",
        "This notebook implements a comprehensive multi-agent system for Databricks migration planning using DSPy, Vector Search, and MLflow deployment.\n",
        "\n",
        "## System Architecture:\n",
        "- **Goal Clarification Agent**: Helps users articulate migration goals\n",
        "- **Question Generation Agent**: Dynamically generates contextual questions\n",
        "- **Information Completeness Scorer**: Evaluates information quality\n",
        "- **Plan Generation Agent**: Creates structured migration plans\n",
        "- **Judge Agent**: Evaluates plan quality using Databricks Judge LLMs\n",
        "- **Excel Export Agent**: Generates structured Excel outputs\n",
        "- **Vector Search**: RAG-based document retrieval\n",
        "- **Lakehouse Storage**: Conversation history persistence\n",
        "\n",
        "## Features:\n",
        "- Multi-agent orchestration with DSPy\n",
        "- Dynamic question prioritization\n",
        "- Information completeness scoring\n",
        "- Structured plan generation with tables\n",
        "- Plan quality evaluation\n",
        "- Excel export with MCP integration\n",
        "- Conversation history in Delta Lake\n",
        "- Vector search for document retrieval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install dspy-ai databricks-vectorsearch openpyxl markitdown\n",
        "\n",
        "# Restart Python to ensure packages are loaded\n",
        "dbutils.library.restartPython()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import dspy\n",
        "import mlflow\n",
        "import json\n",
        "import logging\n",
        "from typing import Dict, Any, List, Optional\n",
        "from datetime import datetime\n",
        "\n",
        "# Databricks specific imports\n",
        "from databricks.vector_search import VectorSearchClient\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit, current_timestamp\n",
        "\n",
        "# System imports\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/Workspace/Repos/varun.bhandary@databricks.com/use-case-delivery-agent')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"migration_planning_system\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CONFIG = {\n",
        "    # Databricks configuration\n",
        "    \"catalog_name\": \"vbdemos\",\n",
        "    \"schema_name\": \"usecase_agent\",\n",
        "    \"vector_search_endpoint\": \"use-case-planning-agent\",\n",
        "    \"vector_search_index\": \"migration_planning_documents\",\n",
        "    \n",
        "    # Model configuration\n",
        "    \"llm_model\": \"databricks/databricks-claude-sonnet-4\",\n",
        "    \"judge_model\": \"databricks-dbrx-instruct\",\n",
        "    \n",
        "    # Data processing\n",
        "    \"pptx_volume_path\": \"/Volumes/vbdemos/dbdemos_autoloader/raw_data/usecase-planning-agent-pdf/\",\n",
        "    \"processed_table\": \"vbdemos.usecase_agent.migration_documents\",\n",
        "    \n",
        "    # Storage\n",
        "    \"conversations_table\": \"vbdemos.usecase_agent.conversation_sessions\",\n",
        "    \"messages_table\": \"vbdemos.usecase_agent.conversation_messages\",\n",
        "    \"interactions_table\": \"vbdemos.usecase_agent.agent_interactions\",\n",
        "    \"evaluations_table\": \"vbdemos.usecase_agent.plan_evaluations\"\n",
        "}\n",
        "\n",
        "print(\"Configuration loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize DSPy and Vector Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure DSPy with Databricks LLM\n",
        "api_key = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
        "workspace_url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().get()\n",
        "\n",
        "lm = dspy.LM(\n",
        "    model=CONFIG[\"llm_model\"],\n",
        "    api_key=api_key,\n",
        "    api_base=f\"https://{workspace_url}/serving-endpoints\",\n",
        "    model_type=\"chat\"\n",
        ")\n",
        "\n",
        "dspy.configure(lm=lm)\n",
        "print(\"DSPy configured successfully with Databricks LLM\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Vector Search Client\n",
        "vsc = VectorSearchClient(disable_notice=True)\n",
        "\n",
        "# Test vector search connection\n",
        "try:\n",
        "    indexes = vsc.list_indexes(endpoint_name=CONFIG[\"vector_search_endpoint\"])\n",
        "    print(f\"Vector Search connected. Found {len(indexes)} indexes.\")\n",
        "except Exception as e:\n",
        "    print(f\"Vector Search connection failed: {str(e)}\")\n",
        "    print(\"Please ensure the vector search endpoint is created and accessible.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Multi-Agent System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import agent components\n",
        "from agents import (\n",
        "    GoalClarificationAgent,\n",
        "    QuestionGenerationAgent,\n",
        "    InformationCompletenessScorer,\n",
        "    PlanGenerationAgent,\n",
        "    PlanQualityJudge,\n",
        "    ExcelExportAgent\n",
        ")\n",
        "from orchestration import WorkflowManager, ConversationManager\n",
        "from data_processing import LakehouseStorage\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"MigrationPlanningSystem\").getOrCreate()\n",
        "\n",
        "# Initialize lakehouse storage\n",
        "lakehouse_storage = LakehouseStorage(\n",
        "    spark_session=spark,\n",
        "    catalog=CONFIG[\"catalog_name\"],\n",
        "    schema=CONFIG[\"schema_name\"]\n",
        ")\n",
        "\n",
        "# Initialize conversation manager\n",
        "conversation_manager = ConversationManager(storage_backend=lakehouse_storage)\n",
        "\n",
        "# Initialize workflow manager\n",
        "workflow_manager = WorkflowManager(\n",
        "    conversation_manager=conversation_manager,\n",
        "    vector_search_endpoint=CONFIG[\"vector_search_endpoint\"],\n",
        "    vector_search_index=CONFIG[\"vector_search_index\"]\n",
        ")\n",
        "\n",
        "print(\"Multi-agent system initialized successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test the System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the system with a sample migration planning session\n",
        "print(\"Testing the migration planning system...\")\n",
        "\n",
        "# Start a planning session\n",
        "session = workflow_manager.start_planning_session(\n",
        "    user_id=\"test_user\",\n",
        "    project_context=\"We need to migrate our Oracle data warehouse to Databricks on Azure. We have 50+ data pipelines, 2TB of data, and need to complete within 6 months.\",\n",
        "    initial_goals=[\"Migrate Oracle to Databricks\", \"Improve performance\", \"Reduce costs\"]\n",
        ")\n",
        "\n",
        "print(f\"Session started: {session.session_id}\")\n",
        "print(f\"Current phase: {session.current_phase}\")\n",
        "print(f\"Goals: {session.goals}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test goal clarification\n",
        "print(\"\\n=== Testing Goal Clarification ===\")\n",
        "response = workflow_manager.process_user_input(\n",
        "    session_id=session.session_id,\n",
        "    user_input=\"We want to migrate our Oracle data warehouse to Databricks for better performance and cost savings.\",\n",
        "    input_type=\"goal_statement\"\n",
        ")\n",
        "\n",
        "print(f\"Response: {response.get('response', 'No response')}\")\n",
        "print(f\"Next action: {response.get('next_action', 'Unknown')}\")\n",
        "print(f\"Phase: {response.get('phase', 'Unknown')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test information gathering\n",
        "print(\"\\n=== Testing Information Gathering ===\")\n",
        "response = workflow_manager.process_user_input(\n",
        "    session_id=session.session_id,\n",
        "    user_input=\"Resource: We have 5 team members with mixed skills. Timeline: We need to complete in 6 months. Scope: 50+ pipelines, 2TB of data.\",\n",
        "    input_type=\"information_answer\"\n",
        ")\n",
        "\n",
        "print(f\"Response: {response.get('response', 'No response')}\")\n",
        "print(f\"Completeness Score: {response.get('completeness_score', 0):.1%}\")\n",
        "print(f\"Quality Score: {response.get('quality_score', 0):.1%}\")\n",
        "print(f\"Ready for Planning: {response.get('ready_for_planning', False)}\")\n",
        "print(f\"Questions: {response.get('questions', [])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test plan generation\n",
        "print(\"\\n=== Testing Plan Generation ===\")\n",
        "response = workflow_manager.process_user_input(\n",
        "    session_id=session.session_id,\n",
        "    user_input=\"Generate the migration plan\",\n",
        "    input_type=\"plan_request\"\n",
        ")\n",
        "\n",
        "print(f\"Response: {response.get('response', 'No response')}\")\n",
        "print(f\"Plan Overview: {response.get('plan_overview', 'No plan')[:200]}...\")\n",
        "print(f\"Next Action: {response.get('next_action', 'Unknown')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test plan evaluation\n",
        "print(\"\\n=== Testing Plan Evaluation ===\")\n",
        "response = workflow_manager.process_user_input(\n",
        "    session_id=session.session_id,\n",
        "    user_input=\"Evaluate the generated plan\",\n",
        "    input_type=\"evaluation_request\"\n",
        ")\n",
        "\n",
        "print(f\"Response: {response.get('response', 'No response')}\")\n",
        "print(f\"Quality Score: {response.get('quality_score', 0):.1f}/10\")\n",
        "print(f\"Grade: {response.get('grade', 'N/A')}\")\n",
        "print(f\"Feedback: {response.get('feedback', 'No feedback')[:200]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Excel export\n",
        "print(\"\\n=== Testing Excel Export ===\")\n",
        "export_result = workflow_manager.export_plan(\n",
        "    session_id=session.session_id,\n",
        "    format_type=\"excel\"\n",
        ")\n",
        "\n",
        "print(f\"Export Success: {export_result.get('success', False)}\")\n",
        "print(f\"File Path: {export_result.get('file_path', 'No path')}\")\n",
        "print(f\"Format: {export_result.get('format', 'Unknown')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. MLflow Model Deployment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure MLflow for Unity Catalog\n",
        "mlflow.set_registry_uri(\"databricks-uc\")\n",
        "\n",
        "# Create a wrapper class for MLflow deployment\n",
        "class MigrationPlanningAgentWrapper(mlflow.pyfunc.PythonModel):\n",
        "    \"\"\"MLflow wrapper for the Migration Planning Agent System.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.workflow_manager = None\n",
        "        self.conversation_manager = None\n",
        "    \n",
        "    def load_context(self, context):\n",
        "        \"\"\"Load the agent system when the model is loaded.\"\"\"\n",
        "        try:\n",
        "            # Reconfigure DSPy\n",
        "            api_key = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
        "            workspace_url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().get()\n",
        "            \n",
        "            lm = dspy.LM(\n",
        "                model=CONFIG[\"llm_model\"],\n",
        "                api_key=api_key,\n",
        "                api_base=f\"https://{workspace_url}/serving-endpoints\",\n",
        "                model_type=\"chat\"\n",
        "            )\n",
        "            dspy.configure(lm=lm)\n",
        "            \n",
        "            # Initialize components\n",
        "            from orchestration import ConversationManager, WorkflowManager\n",
        "            from data_processing import LakehouseStorage\n",
        "            \n",
        "            spark = SparkSession.builder.appName(\"MigrationPlanningAgent\").getOrCreate()\n",
        "            lakehouse_storage = LakehouseStorage(\n",
        "                spark_session=spark,\n",
        "                catalog=CONFIG[\"catalog_name\"],\n",
        "                schema=CONFIG[\"schema_name\"]\n",
        "            )\n",
        "            \n",
        "            self.conversation_manager = ConversationManager(storage_backend=lakehouse_storage)\n",
        "            self.workflow_manager = WorkflowManager(\n",
        "                conversation_manager=self.conversation_manager,\n",
        "                vector_search_endpoint=CONFIG[\"vector_search_endpoint\"],\n",
        "                vector_search_index=CONFIG[\"vector_search_index\"]\n",
        "            )\n",
        "            \n",
        "            print(\"Migration Planning Agent loaded successfully\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading agent: {str(e)}\")\n",
        "            raise e\n",
        "    \n",
        "    def predict(self, model_input, params=None):\n",
        "        \"\"\"Predict method for MLflow serving.\"\"\"\n",
        "        try:\n",
        "            # Handle different input formats\n",
        "            if isinstance(model_input, dict):\n",
        "                if \"messages\" in model_input:\n",
        "                    # Chat format\n",
        "                    user_message = \"\"\n",
        "                    for message in model_input[\"messages\"]:\n",
        "                        if message.get(\"role\") == \"user\":\n",
        "                            user_message = message.get(\"content\", \"\")\n",
        "                            break\n",
        "                    \n",
        "                    # Extract session info\n",
        "                    session_id = model_input.get(\"session_id\", \"default_session\")\n",
        "                    input_type = model_input.get(\"input_type\", \"message\")\n",
        "                    \n",
        "                    # Process with workflow manager\n",
        "                    response = self.workflow_manager.process_user_input(\n",
        "                        session_id=session_id,\n",
        "                        user_input=user_message,\n",
        "                        input_type=input_type\n",
        "                    )\n",
        "                    \n",
        "                    return {\n",
        "                        \"choices\": [\n",
        "                            {\n",
        "                                \"message\": {\n",
        "                                    \"role\": \"assistant\",\n",
        "                                    \"content\": response.get(\"response\", \"No response\")\n",
        "                                }\n",
        "                            }\n",
        "                        ],\n",
        "                        \"session_id\": session_id,\n",
        "                        \"phase\": response.get(\"phase\", \"unknown\"),\n",
        "                        \"next_action\": response.get(\"next_action\", \"continue\")\n",
        "                    }\n",
        "                \n",
        "                else:\n",
        "                    # Direct format\n",
        "                    session_id = model_input.get(\"session_id\", \"default_session\")\n",
        "                    user_input = model_input.get(\"user_input\", \"\")\n",
        "                    input_type = model_input.get(\"input_type\", \"message\")\n",
        "                    \n",
        "                    response = self.workflow_manager.process_user_input(\n",
        "                        session_id=session_id,\n",
        "                        user_input=user_input,\n",
        "                        input_type=input_type\n",
        "                    )\n",
        "                    \n",
        "                    return response\n",
        "            \n",
        "            # String input\n",
        "            elif isinstance(model_input, str):\n",
        "                response = self.workflow_manager.process_user_input(\n",
        "                    session_id=\"default_session\",\n",
        "                    user_input=model_input,\n",
        "                    input_type=\"message\"\n",
        "                )\n",
        "                return response\n",
        "            \n",
        "            else:\n",
        "                return {\"error\": \"Invalid input format\"}\n",
        "                \n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Prediction failed: {str(e)}\"}\n",
        "\n",
        "print(\"MLflow wrapper class defined successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deploy the agent system using MLflow\n",
        "print(\"Deploying Migration Planning Agent System...\")\n",
        "\n",
        "# Input example for the model\n",
        "input_example = {\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"We want to migrate our Oracle data warehouse to Databricks. Can you help us create a migration plan?\"\n",
        "        }\n",
        "    ],\n",
        "    \"session_id\": \"test_session\",\n",
        "    \"input_type\": \"goal_statement\"\n",
        "}\n",
        "\n",
        "# Log the model to MLflow\n",
        "with mlflow.start_run() as run:\n",
        "    logged_model_info = mlflow.pyfunc.log_model(\n",
        "        python_model=MigrationPlanningAgentWrapper(),\n",
        "        artifact_path=\"migration-planning-agent\",\n",
        "        input_example=input_example,\n",
        "        pip_requirements=[\n",
        "            \"dspy-ai>=2.4.0\",\n",
        "            \"databricks-vectorsearch>=0.1.0\",\n",
        "            \"openpyxl>=3.1.0\",\n",
        "            \"markitdown>=0.1.0\"\n",
        "        ],\n",
        "        env_vars={\n",
        "            \"VECTOR_SEARCH_ENDPOINT\": CONFIG[\"vector_search_endpoint\"],\n",
        "            \"VECTOR_SEARCH_INDEX\": CONFIG[\"vector_search_index\"],\n",
        "            \"CATALOG_NAME\": CONFIG[\"catalog_name\"],\n",
        "            \"SCHEMA_NAME\": CONFIG[\"schema_name\"]\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ Agent logged to MLflow: {logged_model_info.model_uri}\")\n",
        "\n",
        "# Register the model in Unity Catalog\n",
        "model_name = f\"{CONFIG['catalog_name']}.{CONFIG['schema_name']}.migration-planning-agent\"\n",
        "uc_model_info = mlflow.register_model(\n",
        "    model_uri=logged_model_info.model_uri,\n",
        "    name=model_name\n",
        ")\n",
        "\n",
        "print(f\"✅ Agent registered in Unity Catalog: {uc_model_info.name}\")\n",
        "print(f\"   Version: {uc_model_info.version}\")\n",
        "print(f\"✅ Agent ready for deployment!\")\n",
        "print(f\"📊 Model URI: {logged_model_info.model_uri}\")\n",
        "print(f\"🏷️ Registered as: {uc_model_info.name}\")\n",
        "print(f\"📈 Next step: Deploy via Databricks Model Serving UI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. System Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# System Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎯 AGENTIC MIGRATION PLANNING SYSTEM - DEPLOYMENT COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"📊 Model Registered: {uc_model_info.name}\")\n",
        "print(f\"🔢 Version: {uc_model_info.version}\")\n",
        "print(f\"🔗 Model URI: {logged_model_info.model_uri}\")\n",
        "print(f\"📈 Vector Search Endpoint: {CONFIG['vector_search_endpoint']}\")\n",
        "print(f\"🗂️ Vector Search Index: {CONFIG['vector_search_index']}\")\n",
        "print(f\"💾 Storage: {CONFIG['catalog_name']}.{CONFIG['schema_name']}\")\n",
        "print(\"\\n🚀 NEXT STEPS:\")\n",
        "print(\"1. Deploy the model via Databricks Model Serving UI\")\n",
        "print(\"2. Test the deployed endpoint with sample requests\")\n",
        "print(\"3. Monitor performance and usage analytics\")\n",
        "print(\"4. Scale based on usage patterns\")\n",
        "print(\"\\n✨ The system is ready for production use!\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
