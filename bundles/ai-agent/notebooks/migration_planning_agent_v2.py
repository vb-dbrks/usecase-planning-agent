# Databricks notebook source
# MAGIC %md
# MAGIC # Migration Planning Agent V2 - Simplified Design
# MAGIC
# MAGIC This notebook implements a simplified DSPy-based migration planning agent with 4 specialized agents and 7 signatures.

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Setup and Configuration

# COMMAND ----------

# Install required packages with version pinning for DBR 16.4 LTS compatibility
# %pip install dspy>=2.6.23 databricks-vectorsearch mlflow databricks-agents mem0ai

# Restart Python to ensure packages are loaded
# dbutils.library.restartPython()

# COMMAND ----------

# Import required libraries
import dspy
import mlflow
import mlflow.dspy
from databricks.vector_search.client import VectorSearchClient
import json
from typing import List, Dict, Any
import pydantic
import logging
from datetime import datetime

# Check versions for DBR 16.4 LTS compatibility

print(f"DSPy version: {dspy.__version__}")
print(f"Pydantic version: {pydantic.__version__}")
print(f"MLflow version: {mlflow.__version__}")
print("Version compatibility check completed")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Get Parameters

# COMMAND ----------

# # Get parameters from job configuration
# vector_search_endpoint = dbutils.widgets.text("vector_search_endpoint","usecase-agent")
# vector_index_name = dbutils.widgets.text("vector_index_name","vbdemos.usecase_agent.migration_planning_documents")
# agent_model = dbutils.widgets.text("agent_model","databricks-claude-3-7-sonnet")
# mlflow_experiment_name = dbutils.widgets.text("mlflow_experiment_name","/Users/varun.bhandary@databricks.com/usecase-agent")


# Get parameters from job configuration
vector_search_endpoint = dbutils.widgets.get("vector_search_endpoint")
vector_index_name = dbutils.widgets.get("vector_index_name")
agent_model = dbutils.widgets.get("agent_model")
mlflow_experiment_name = dbutils.widgets.get("mlflow_experiment_name")

print(f"Vector search endpoint: {vector_search_endpoint}")
print(f"Vector index name: {vector_index_name}")
print(f"Agent model: {agent_model}")
print(f"MLflow experiment name: {mlflow_experiment_name}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. DSPy Setup and Model Configuration

# COMMAND ----------

# Configure DSPy with Databricks model
token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()
url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get() + '/serving-endpoints'

lm = dspy.LM(
    model="databricks/databricks-claude-sonnet-4",
    api_key=token,
    api_base=url,
)

# Configure DSPy
dspy.configure(lm=lm)

print(f"DSPy version: {dspy.__version__}")
print("DSPy configured successfully with Databricks model")

# Initialize Vector Search client
vsc = VectorSearchClient()
print("DSPy and Vector Search configured successfully!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. DSPy Signatures (7 Total)

# COMMAND ----------

# Core DSPy Signatures (7 Total)

# User Interaction Signatures
class IntentClassifier(dspy.Signature):
    """Classify user intent from their input."""
    user_input: str = dspy.InputField(desc="The user's input")
    conversation_context: str = dspy.InputField(desc="Previous conversation context")
    intent: str = dspy.OutputField(desc="Classified intent: greeting, general_question, project_context_provided, answers_provided, request_plan, or unknown")
    confidence: float = dspy.OutputField(desc="Confidence score between 0 and 1")

class GreetingHandler(dspy.Signature):
    """Handle greetings and explain use case delivery planning capabilities for Databricks account teams."""
    user_input: str = dspy.InputField(desc="The user's input")
    response: str = dspy.OutputField(desc="Use Case Delivery Planning Agent greeting explaining capabilities for Databricks account teams")

class MemoryAwareQA(dspy.Signature):
    """You're a migration planning assistant with access to memory. Use stored information to provide context-aware responses."""
    user_input: str = dspy.InputField(desc="The user's input")
    stored_memories: str = dspy.InputField(desc="Relevant memories from previous conversations")
    response: str = dspy.OutputField(desc="Context-aware response using memory information")

# Question Generation Signatures - Memory-Aware
class QuestionGenerator(dspy.Signature):
    """Generate targeted questions for migration planning based on stored memories and context."""
    user_input: str = dspy.InputField(desc="The user's input")
    stored_memories: str = dspy.InputField(desc="Relevant memories from previous conversations")
    questions: str = dspy.OutputField(desc="Generate 3-5 specific questions about migration planning, each on a new line starting with a number")
    category: str = dspy.OutputField(desc="The category these questions belong to")
    reasoning: str = dspy.OutputField(desc="Reasoning for why these questions were generated")

# Information Processing Signatures - Simplified for Memory Integration
class DataAccumulator(dspy.Signature):
    """Extract and structure key information from user input for migration planning."""
    user_input: str = dspy.InputField(desc="The user's input or response")
    structured_data: str = dspy.OutputField(desc="Key information extracted in structured format")

class InformationSummarizer(dspy.Signature):
    """Summarize collected information to provide context for planning."""
    collected_data: str = dspy.InputField(desc="All collected data from memory")
    summary: str = dspy.OutputField(desc="Clear summary of collected information for planning")

class InformationQualityAssessor(dspy.Signature):
    """Assess the quality and completeness of collected information for migration planning."""
    collected_data: str = dspy.InputField(desc="All collected data in JSON format")
    summary: str = dspy.InputField(desc="Current summary of information")
    required_categories: str = dspy.InputField(desc="Required planning categories in JSON format")
    completeness_score: float = dspy.OutputField(desc="Completeness score between 0 and 1 (need at least 0.7 for planning)")
    missing_areas: str = dspy.OutputField(desc="Critical missing areas that prevent planning")
    assumptions: str = dspy.OutputField(desc="Assumptions made based on available information")
    ready_for_planning: bool = dspy.OutputField(desc="Only true if completeness_score >= 0.7 and key areas covered")
    confidence_level: str = dspy.OutputField(desc="Confidence level: high (>=0.8), medium (0.6-0.8), low (<0.6)")

# Plan Generation Signatures
class PlanGenerator(dspy.Signature):
    """Generate comprehensive migration plan with all required sections."""
    collected_data: str = dspy.InputField(desc="All collected data in JSON format")
    summary: str = dspy.InputField(desc="Summary of collected information")
    relevant_documents: str = dspy.InputField(desc="Relevant documents from vector search")
    reasoning: str = dspy.OutputField(desc="Reasoning for the migration plan approach")
    migration_plan: str = dspy.OutputField(desc="Detailed migration plan with phases and activities")
    timeline: str = dspy.OutputField(desc="Detailed timeline with specific phases, durations, and milestones")
    resource_requirements: str = dspy.OutputField(desc="Required resources including team size, roles, and skills")
    risks: str = dspy.OutputField(desc="Identified risks, their impact, and mitigation strategies")

class PlanEvaluator(dspy.Signature):
    """Evaluate the quality and completeness of the generated plan."""
    plan: str = dspy.InputField(desc="The generated migration plan")
    collected_data: str = dspy.InputField(desc="Original collected data for comparison")
    quality_score: float = dspy.OutputField(desc="Overall quality score between 0 and 100")
    gaps: str = dspy.OutputField(desc="Gaps or missing elements in the plan")
    recommendations: str = dspy.OutputField(desc="Recommendations for improvement")


print("All 7 DSPy signatures defined successfully!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Planning Categories (Institutional Knowledge)

# COMMAND ----------

# PLANNING_CATEGORIES - Institutional knowledge from Databricks Professional Services
PLANNING_CATEGORIES = {
    "Resource & Team": [
        "How many team members are there and what are their roles?",
        "Are the teams sufficiently skilled/trained in Databricks?",
        "Are they using Professional Services or System Integrators?",
        "Are resources shared with other projects?",
        "Have resources done this type of migration work before?"
    ],
    "Customer Background & Drivers": [
        "Does the customer have a specific deadline and what drives it?",
        "Is the customer already using cloud infrastructure?",
        "Does the customer have Databricks elsewhere in the organization?",
        "Does the customer have security approval for this migration?",
        "What are the key business drivers for the migration?"
    ],
    "Technical Scope & Architecture": [
        "Has a pilot or POC been conducted?",
        "Does the customer have visibility of all data and pipelines to migrate?",
        "Is the customer aware of where and who uses the data?",
        "Is lift and shift or redesign preferred for different components?",
        "How many pipelines, reports, and data sources need migration?"
    ],
    "Current Process Maturity": [
        "What is the current data governance and quality process?",
        "How mature is the current data architecture?",
        "What are the current data security and compliance processes?",
        "How is data lineage currently tracked?",
        "What are the current data quality monitoring processes?"
    ],
    "Performance & Scalability": [
        "What are the current performance requirements?",
        "What is the expected data growth rate?",
        "What are the peak usage patterns?",
        "What are the current performance bottlenecks?",
        "What are the target performance and scalability requirements?"
    ],
    "Security & Compliance": [
        "What are the current security requirements?",
        "What compliance standards must be met?",
        "What are the data residency and sovereignty requirements?",
        "What are the access control requirements?",
        "What are the audit and monitoring requirements?"
    ]
}

print("Planning categories defined successfully!")
print(f"Categories: {list(PLANNING_CATEGORIES.keys())}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. Persistent Storage for Information Collection

# COMMAND ----------

# Memory-enabled storage using Mem0 for persistent information management
from mem0 import Memory
import uuid
from datetime import datetime

class MemoryEnabledStorage:
    """Memory-enabled storage using Mem0 for persistent information management."""
    
    def __init__(self, conversation_id=None):
        # Generate unique conversation ID if not provided
        self.conversation_id = conversation_id or f"conv_{uuid.uuid4().hex[:8]}_{int(datetime.now().timestamp())}"
        self.memory = None
        
        try:
            # Configure Mem0 with the same Databricks model as DSPy
            config = {
                "llm": {
                    "provider": "databricks",
                    "config": {
                        "model": "databricks/databricks-claude-sonnet-4",
                        "temperature": 0.1,
                        "api_key": token,
                        "api_base": url
                    }
                },
                "embedder": {
                    "provider": "databricks",
                    "config": {
                        "model": "databricks/databricks-claude-sonnet-4",
                        "api_key": token,
                        "api_base": url
                    }
                }
            }
            self.memory = Memory.from_config(config)
            print(f"‚úÖ Mem0 memory system initialized successfully for conversation: {self.conversation_id}")
            print(f"   Using same model as DSPy: databricks/databricks-claude-sonnet-4")
        except Exception as e:
            raise RuntimeError(f"Failed to initialize Mem0 memory system: {e}. Please install with: pip install mem0ai")
    
    def store_information(self, content, metadata=None):
        """Store information in memory."""
        try:
            # Add metadata for better organization
            full_content = f"Migration Planning Information: {content}"
            if metadata:
                full_content += f" | Metadata: {metadata}"
            
            self.memory.add(full_content, user_id=self.conversation_id)
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è Mem0 storage failed: {e}")
            return False
    
    def search_information(self, query, limit=5):
        """Search for relevant information."""
        try:
            results = self.memory.search(query, user_id=self.conversation_id, limit=limit)
            if results and "results" in results:
                return [result["memory"] for result in results["results"]]
            return []
        except Exception as e:
            print(f"‚ö†Ô∏è Mem0 search failed: {e}")
            return []
    
    def get_all_information(self):
        """Get all stored information."""
        try:
            results = self.memory.get_all(user_id=self.conversation_id)
            if results and "results" in results:
                return [result["memory"] for result in results["results"]]
            return []
        except Exception as e:
            print(f"‚ö†Ô∏è Mem0 retrieval failed: {e}")
            return []
    
    def get_conversation_state(self):
        """Get conversation state from memory."""
        try:
            # Search for state information
            state_results = self.memory.search("conversation state", user_id=self.conversation_id, limit=1)
            if state_results and "results" in state_results and state_results["results"]:
                # Parse state from memory
                state_content = state_results["results"][0]["memory"]
                # Extract state information (simplified parsing)
                return {
                    "project_context": self._extract_from_memory("project_context"),
                    "conversation_stage": self._extract_from_memory("conversation_stage") or "initial",
                    "plan_generated": self._extract_from_memory("plan_generated") == "true"
                }
        except Exception as e:
            print(f"‚ö†Ô∏è State retrieval failed: {e}")
        
        # Default state
        return {
            "project_context": "",
            "conversation_stage": "initial", 
            "plan_generated": False
        }
    
    def update_conversation_state(self, updates):
        """Update conversation state in memory."""
        for key, value in updates.items():
            self.store_information(f"conversation_state_{key}: {value}")
    
    def _extract_from_memory(self, key):
        """Extract specific information from memory."""
        try:
            results = self.memory.search(f"conversation_state_{key}", user_id=self.conversation_id, limit=1)
            if results and "results" in results and results["results"]:
                content = results["results"][0]["memory"]
                # Extract value after the colon
                if ":" in content:
                    return content.split(":", 1)[1].strip()
        except Exception as e:
            print(f"‚ö†Ô∏è Extraction failed for {key}: {e}")
        return None

# Global memory storage instance - will be created per conversation
memory_storage = None

print("Conversation storage initialized successfully!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. Agent Implementations

# COMMAND ----------

# NEW MODULAR AGENT ARCHITECTURE

# 1. User Interaction Agent
class UserInteractionAgent(dspy.Module):
    """Handles user interaction, intent detection, and conversation routing."""
    
    def __init__(self):
        super().__init__()
        self.intent_classifier = dspy.ChainOfThought(IntentClassifier)
        self.greeting_handler = dspy.ChainOfThought(GreetingHandler)
    
    def forward(self, user_input, conversation_context=""):
        """Process user input and route to appropriate next agent following design flow."""
        print(f"üîç UserInteractionAgent: Processing input: '{user_input[:50]}...'")
        
        # Classify user intent using proper DSPy calling convention
        intent_result = self.intent_classifier(
            user_input=str(user_input),
            conversation_context=str(conversation_context)
        )
        
        print(f"üéØ UserInteractionAgent: Intent = '{intent_result.intent}' (confidence: {intent_result.confidence:.2f})")
        
        if intent_result.intent == "greeting" or intent_result.intent == "general_question":
            # Direct handoff to GreetingHandler - return response directly
            print("üëã UserInteractionAgent: Routing to GreetingHandler")
            greeting_result = self.greeting_handler(user_input=str(user_input))
            print("‚úÖ UserInteractionAgent: Returning greeting response directly")
            return greeting_result.response
            
        elif intent_result.intent == "project_context_provided":
            # Return handoff signal for main agent to process
            print("üìù UserInteractionAgent: Returning handoff signal for information collection")
            return {
                "action": "collect_information",
                "user_input": user_input,
                "intent": intent_result.intent
            }
            
        elif intent_result.intent == "answers_provided":
            # Return handoff signal for main agent to process
            print("üìù UserInteractionAgent: Returning handoff signal for information collection")
            return {
                "action": "collect_information", 
                "user_input": user_input,
                "intent": intent_result.intent
            }
            
        elif intent_result.intent == "request_plan":
            # Return handoff signal for main agent to process
            print("üìã UserInteractionAgent: Returning handoff signal for plan generation")
            return {
                "action": "generate_plan",
                "user_input": user_input,
                "intent": intent_result.intent
            }
            
        else:
            # Unknown intent - ask for clarification
            print("‚ùì UserInteractionAgent: Unknown intent - asking for clarification")
            return "I'm not sure how to help with that. Could you please clarify what you need?"

# 2. Question Generator Agent
class QuestionGeneratorAgent(dspy.Module):
    """Generates targeted questions based on available context."""
    
    def __init__(self):
        super().__init__()
        self.question_generator = dspy.ChainOfThought(QuestionGenerator)
        self.asked_questions = set()  # Track asked questions
    
    def generate_questions(self, user_input, stored_memories):
        print(f"‚ùì QuestionGeneratorAgent: Generating questions for input: '{user_input[:50]}...'")
        
        try:
            # Generate questions based on user input and stored memories
            result = self.question_generator(
                user_input=str(user_input),
                stored_memories=str(stored_memories)
            )
            print(f"üìù QuestionGeneratorAgent: Generated questions in category: '{result.category}'")
            
            
            # Filter out semantically similar questions
            filtered_questions = self._filter_similar_questions(result.questions)
            
            # Ensure we have valid questions
            if not filtered_questions or len(filtered_questions.split("\n")) < 3:
                print(f"‚ö†Ô∏è QuestionGeneratorAgent: Using fallback questions due to insufficient generated questions")
                filtered_questions = """1. What is the customer's current data volume and system complexity?
2. What are the target timeline and key milestones for this delivery?
3. What are the customer's main business objectives and success criteria?
4. What is the customer's team size and their Databricks experience level?
5. What are the performance requirements and compliance constraints?"""
            
            
            return dspy.Prediction(
                questions=filtered_questions,
                category=result.category,
                reasoning=result.reasoning
            )
        except Exception as e:
            # Fallback to default questions if generation fails
            return dspy.Prediction(
                questions="""1. What is the customer's current data volume and system complexity?
2. What are the target timeline and key milestones for this delivery?
3. What are the customer's main business objectives and success criteria?
4. What is the customer's team size and their Databricks experience level?
5. What are the performance requirements and compliance constraints?""",
                category="Migration Planning",
                reasoning="Default questions provided due to generation error"
            )
    
    def _filter_similar_questions(self, questions):
        """Remove questions that are semantically similar to already asked ones."""
        # Handle both string and list inputs
        if isinstance(questions, str):
            # Split string into list of questions
            question_list = [q.strip() for q in questions.split('\n') if q.strip()]
        elif isinstance(questions, list):
            question_list = questions
        else:
            question_list = [str(questions)]
        
        filtered = []
        for question in question_list:
            if question and not self._is_similar_to_asked(question):
                filtered.append(question)
                self.asked_questions.add(question)
        
        # Return as string with newlines
        return '\n'.join(filtered)
    
    def _is_similar_to_asked(self, question):
        """Check if question is similar to already asked questions."""
        # Simple similarity check - can be enhanced with embeddings
        question_lower = question.lower()
        for asked in self.asked_questions:
            if self._calculate_similarity(question_lower, asked.lower()) > 0.7:
                return True
        return False
    
    def _calculate_similarity(self, text1, text2):
        """Simple similarity calculation."""
        words1 = set(text1.split())
        words2 = set(text2.split())
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        return len(intersection) / len(union) if union else 0
    
    def generate_questions_response(self, user_input, stored_memories):
        """Direct handoff from InformationQualityAgent following design flow."""
        print(f"‚ùì QuestionGeneratorAgent: Starting question generation flow")
        print(f"   Input: '{user_input[:50]}...', Memories: {len(stored_memories)} items")
        
        # Generate questions
        question_result = self.generate_questions(user_input, stored_memories)
        print(f"üìù QuestionGeneratorAgent: Generated questions in category: '{question_result.category}'")
        
        # Format and return questions
        questions_text = self._format_questions(question_result.questions)
        print(f"‚úÖ QuestionGeneratorAgent: Returning formatted questions")
        
        # Ensure we always have questions
        if not questions_text or len(questions_text.strip()) < 50:
            questions_text = """1. What is the customer's current data volume and system complexity?
2. What are the target timeline and key milestones for this delivery?
3. What are the customer's main business objectives and success criteria?
4. What is the customer's team size and their Databricks experience level?
5. What are the performance requirements and compliance constraints?"""
            print("‚ö†Ô∏è QuestionGeneratorAgent: Using fallback questions")
        
        return f"""**Got it! Thanks for that information.**

**To create a better plan, I need to know more about:**
{questions_text}

*Please provide answers to these questions, or use `/status` to see progress.*"""
    
    def _format_questions(self, questions):
        """Format questions properly from the question generator."""
        # Default questions for migration planning
        default_questions = """1. What is the customer's current data volume and system complexity?
2. What are the target timeline and key milestones for this delivery?
3. What are the customer's main business objectives and success criteria?
4. What is the customer's team size and their Databricks experience level?
5. What are the performance requirements and compliance constraints?"""
        
        if isinstance(questions, str):
            # Clean up the string
            questions = questions.strip()
            
            # Check if it's empty or just numbers
            if not questions or questions.count(".") > 10 or len(questions.split("\n")) < 3:
                return default_questions
            
            # Handle character array format
            if questions.startswith("['") and questions.endswith("']"):
                clean_questions = questions[2:-2].replace("', '", "\n").replace("'", "")
                if len(clean_questions.strip()) > 0:
                    return clean_questions
                else:
                    return default_questions
            
            # Check if it has actual content (not just numbers)
            lines = questions.split("\n")
            content_lines = [line for line in lines if line.strip() and not line.strip().replace(".", "").replace(" ", "").isdigit()]
            
            if len(content_lines) < 2:
                return default_questions
            
            return questions
            
        elif isinstance(questions, list):
            # Filter out empty items
            valid_questions = [q.strip() for q in questions if q.strip() and not q.strip().replace(".", "").replace(" ", "").isdigit()]
            
            if len(valid_questions) < 2:
                return default_questions
            
            return "\n".join([f"{i+1}. {q}" for i, q in enumerate(valid_questions)])
        else:
            return default_questions

# 3. Information Collector Agent
class InformationCollectorAgent(dspy.Module):
    """Collects and summarizes information from user interactions."""
    
    def __init__(self, vector_search_endpoint, vector_index, quality_agent=None, question_agent=None, conversation_id=None):
        super().__init__()
        self.data_accumulator = dspy.ChainOfThought(DataAccumulator)
        self.summarizer = dspy.ChainOfThought(InformationSummarizer)
        self.vector_search = VectorSearchClient()
        self.endpoint = vector_search_endpoint
        self.index = vector_index
        self.conversation_id = conversation_id
        self.quality_agent = quality_agent
        self.question_agent = question_agent
    
    def collect_information(self, user_input, context="", memory_storage=None):
        """Collect and process new information from user using memory-enabled storage."""
        print(f"üìä InformationCollectorAgent: Starting data collection")
        print(f"   Input: '{user_input[:50]}...', Context length: {len(context)}")
        
        # Extract structured data from user input
        accumulator_result = self.data_accumulator(user_input=str(user_input))
        structured_data = accumulator_result.structured_data
        
        # Store the structured information in memory
        if memory_storage:
            memory_storage.store_information(
                content=structured_data,
                metadata={"context": context, "timestamp": str(datetime.now()), "type": "structured_data"}
            )
            
            # Get all stored information for context
            all_information = memory_storage.get_all_information()
            print(f"üìö InformationCollectorAgent: Retrieved {len(all_information)} stored information items")
        else:
            # Fallback if no memory storage provided
            all_information = [structured_data]
            print(f"üìö InformationCollectorAgent: No memory storage, using current input only")
        
        # Create a summary of all information
        if all_information:
            # Use the summarizer to create a comprehensive summary
            summary_result = self.summarizer(
                collected_data=str(json.dumps(all_information))
            )
            summarized_info = summary_result.summary
        else:
            summarized_info = "No information collected yet."
        
        print(f"üìÑ InformationCollectorAgent: Updated summary, length: {len(summarized_info)} characters")
        
        # Search for relevant documents
        docs_result = self._search_documents(user_input)
        
        return dspy.Prediction(
            collected_data=all_information,
            summary=summarized_info,
            relevant_documents=docs_result,
            data_count=len(all_information)
        )
    
    def process_information(self, user_input, context="", memory_storage=None):
        """Direct handoff from UserInteractionAgent following design flow."""
        print(f"üìä InformationCollectorAgent: Starting information collection flow")
        print(f"   Input: '{user_input[:50]}...'")
        
        # Collect information
        collection_result = self.collect_information(user_input, context, memory_storage)
        print(f"üìà InformationCollectorAgent: Collected {len(collection_result.collected_data)} data items")
        
        # Hand off directly to InformationQualityAgent
        if self.quality_agent:
            print("üîÑ InformationCollectorAgent ‚Üí InformationQualityAgent (Direct Handoff)")
            # Get stored memories for context
            stored_memories = memory_storage.get_all_information() if memory_storage else []
            return self.quality_agent.process_quality(
                collection_result.collected_data, 
                collection_result.summary, 
                user_input, 
                stored_memories
            )
        else:
            # Fallback if no quality agent available
            print("‚ö†Ô∏è InformationCollectorAgent: No quality agent available, returning collection result")
            return f"Collected information: {collection_result.summary[:200]}..."
    
    def _search_documents(self, query):
        """Search for relevant documents."""
        try:
            search_results = self.vector_search.get_index(
                endpoint_name=self.endpoint,
                index_name=self.index
            ).query(
                query_text=query,
                columns=["content", "title", "category", "source"],
                num_results=3
            )
            
            formatted_docs = []
            for doc in search_results.get('result', {}).get('data_array', []):
                formatted_docs.append(f"Title: {doc[1]}\nContent: {doc[0][:300]}...")
            
            return "\n\n".join(formatted_docs)
        except Exception as e:
            return f"Document search error: {str(e)}"

# 4. Information Quality Agent
class InformationQualityAgent(dspy.Module):
    """Assesses quality and completeness of collected information."""
    
    def __init__(self, question_agent=None, planner_agent=None):
        super().__init__()
        self.quality_assessor = dspy.ChainOfThought(InformationQualityAssessor)
        self.question_agent = question_agent
        self.planner_agent = planner_agent
    
    def assess_quality(self, collected_data, summary):
        """Assess if we have enough information for planning."""
        print(f"üîç InformationQualityAgent: Assessing quality of {len(collected_data)} data items")
        
        result = self.quality_assessor(
            collected_data=str(json.dumps(collected_data)),
            summary=str(summary),
            required_categories=str(json.dumps(list(PLANNING_CATEGORIES.keys())))
        )
        
        print(f"üìä InformationQualityAgent: Quality assessment complete - Score: {result.completeness_score:.2f}, Ready: {result.ready_for_planning}")
        
        
        return dspy.Prediction(
            completeness_score=result.completeness_score,
            missing_areas=result.missing_areas,
            assumptions=result.assumptions,
            ready_for_planning=result.ready_for_planning,
            confidence_level=result.confidence_level
        )
    
    def process_quality(self, collected_data, summary, user_input="", stored_memories=""):
        """Direct handoff from InformationCollectorAgent following design flow."""
        print(f"üîç InformationQualityAgent: Starting quality assessment flow")
        print(f"   Data items: {len(collected_data)}, Summary length: {len(summary)}")
        
        # Assess quality
        quality_result = self.assess_quality(collected_data, summary)
        print(f"üìä InformationQualityAgent: Completeness = {quality_result.completeness_score:.2f}, Ready = {quality_result.ready_for_planning}")
        
        # Decision point: Ready for planning or need more questions?
        if quality_result.ready_for_planning and quality_result.completeness_score >= 0.7:
            print("‚úÖ InformationQualityAgent ‚Üí PlannerAgent (Ready for Planning)")
            if self.planner_agent:
                return self.planner_agent.generate_plan(collected_data, summary, "")
            else:
                return f"Ready for planning! Completeness: {quality_result.completeness_score:.0%}"
        else:
            print("‚ùì InformationQualityAgent ‚Üí QuestionGeneratorAgent (Need More Info)")
            if self.question_agent:
                return self.question_agent.generate_questions_response(user_input, stored_memories)
            else:
                return f"Need more information. Completeness: {quality_result.completeness_score:.0%}"

# 5. Planner Agent
class PlannerAgent(dspy.Module):
    """Generates migration plans based on collected information."""
    
    def __init__(self):
        super().__init__()
        self.plan_generator = dspy.ChainOfThought(PlanGenerator)
        self.evaluator = dspy.ChainOfThought(PlanEvaluator)
    
    def generate_plan(self, collected_data, summary, relevant_documents):
        """Generate comprehensive migration plan."""
        print(f"üìã PlannerAgent: Starting plan generation process")
        print(f"   Data items: {len(collected_data)}, Summary length: {len(summary)}")
        
        try:
            # Generate plan
            print(f"üîÑ PlannerAgent: Generating migration plan")
            plan_result = self.plan_generator(
                collected_data=str(json.dumps(collected_data)),
                summary=str(summary),
                relevant_documents=str(relevant_documents)
            )
            print(f"‚úÖ PlannerAgent: Plan generation completed, evaluating quality")
            
            
            # Ensure all required fields are present
            reasoning = getattr(plan_result, 'reasoning', 'Migration plan generated based on available information')
            migration_plan = getattr(plan_result, 'migration_plan', 'Migration plan not generated')
            timeline = getattr(plan_result, 'timeline', 'Timeline not specified')
            resource_requirements = getattr(plan_result, 'resource_requirements', 'Resource requirements not specified')
            risks = getattr(plan_result, 'risks', 'Risk assessment not completed')
            
            # Evaluate plan
            print(f"üîç PlannerAgent: Evaluating plan quality")
            eval_result = self.evaluator(
                plan=str(migration_plan),
                collected_data=str(json.dumps(collected_data))
            )
            print(f"üìä PlannerAgent: Plan evaluation complete - Quality score: {eval_result.quality_score}/100")
            
            
            return dspy.Prediction(
                reasoning=reasoning,
                migration_plan=migration_plan,
                timeline=timeline,
                resource_requirements=resource_requirements,
                risks=risks,
                quality_score=eval_result.quality_score,
                gaps=eval_result.gaps,
                recommendations=eval_result.recommendations
            )
        except Exception as e:
            # Fallback if plan generation fails
            return dspy.Prediction(
                reasoning="Unable to generate detailed plan due to insufficient information",
                migration_plan="Please provide more specific information about your migration requirements",
                timeline="Timeline cannot be determined without more details",
                resource_requirements="Resource requirements need more project details",
                risks="Risk assessment requires more project information",
                quality_score=0.0,
                gaps="Insufficient information for comprehensive planning",
                recommendations="Please provide more details about your migration project"
            )

    def forward(self, collected_data, summary, relevant_documents=""):
        """Direct handoff from InformationQualityAgent following design flow."""
        print(f"üìã PlannerAgent: Starting plan generation flow")
        print(f"   Data items: {len(collected_data)}, Summary length: {len(summary)}")
        
        # Generate plan
        plan_result = self.generate_plan(collected_data, summary, relevant_documents)
        print(f"‚úÖ PlannerAgent: Generated plan with quality score: {plan_result.quality_score}/100")
        
        # Format the plan with proper structure
        formatted_plan = f"""
# Migration Plan

## Project Overview
{plan_result.migration_plan}

## Migration Timeline
{plan_result.timeline}

## Resource Requirements
{plan_result.resource_requirements}

## Risk Assessment
{plan_result.risks}

---
**Plan Quality Metrics:**
- Quality Score: {plan_result.quality_score}/100
- Identified Gaps: {plan_result.gaps}
- Recommendations: {plan_result.recommendations}
"""
        
        print(f"üéØ PlannerAgent: Returning formatted migration plan")
        return formatted_plan


print("All 4 agents implemented successfully!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7.1. Simplified MVP Components
# MAGIC 
# MAGIC This section implements the simplified MVP approach with:
# MAGIC 1. **SimpleStorage**: Two in-memory objects for conversation and summary
# MAGIC 2. **ConversationManager**: Handles all 4 user flows
# MAGIC 3. **Question Categories**: Predefined questions from colleague
# MAGIC 4. **Preserved MLflow**: Keeps existing deployment pipeline

# COMMAND ----------

# Simplified MVP Components

class SimpleStorage:
    """Simple in-memory storage for MVP demo."""
    
    def __init__(self):
        self.conversation_history = []
        self.information_summary = ""
        self.current_questions = []
        self.questions_asked = set()
    
    def add_conversation(self, user_input, agent_response):
        """Add conversation turn to history."""
        self.conversation_history.append({
            "user": user_input,
            "agent": agent_response,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })
    
    def update_summary(self, new_info):
        """Update information summary with new details."""
        if self.information_summary:
            self.information_summary += f"\n\nAdditional Information: {new_info}"
        else:
            self.information_summary = f"Project Information: {new_info}"
    
    def get_summary(self):
        """Get current information summary."""
        return self.information_summary
    
    def get_conversation_context(self):
        """Get recent conversation context."""
        if len(self.conversation_history) <= 3:
            return self.conversation_history
        return self.conversation_history[-3:]  # Last 3 turns

# Question Categories for MVP (from colleague)
QUESTION_CATEGORIES = {
    "Resource & Team": [
        "How many team members are there and what are their roles?",
        "Are the teams sufficiently skilled/trained in Databricks?",
        "Are they using Professional Services or System Integrators?",
        "Are resources shared with other projects?",
        "Have resources done this type of migration work before?"
    ],
    "Customer Background & Drivers": [
        "Does the customer have a specific deadline and what drives it?",
        "Is the customer already using cloud infrastructure?",
        "Does the customer have Databricks elsewhere in the organization?",
        "Does the customer have security approval for this migration?",
        "What are the key business drivers for the migration?"
    ],
    "Technical Scope & Architecture": [
        "Has a pilot or POC been conducted?",
        "Does the customer have visibility of all data and pipelines to migrate?",
        "Is the customer aware of where and who uses the data?",
        "Is lift and shift or redesign preferred for different components?",
        "How many pipelines, reports, and data sources need migration?"
    ],
    "Current Process Maturity": [
        "What is the current data governance and quality process?",
        "How mature is the current data architecture?",
        "What are the current data security and compliance processes?",
        "How is data lineage currently tracked?",
        "What are the current data quality monitoring processes?"
    ],
    "Performance & Scalability": [
        "What are the current performance requirements?",
        "What is the expected data growth rate?",
        "What are the peak usage patterns?",
        "What are the current performance bottlenecks?",
        "What are the target performance and scalability requirements?"
    ],
    "Security & Compliance": [
        "What are the current security requirements?",
        "What compliance standards must be met?",
        "What are the data residency and sovereignty requirements?",
        "What are the access control requirements?",
        "What are the audit and monitoring requirements?"
    ]
}

# COMMAND ----------

# Simplified DSPy Signatures for MVP
class GreetingSignature(dspy.Signature):
    """Handle greetings and explain capabilities of the Use Case Planning Agent for Databricks Account teams."""
    user_input: str = dspy.InputField(desc="The user's input")
    response: str = dspy.OutputField(desc="Greeting response explaining Use Case Planning Agent capabilities")

class InformationCollectorSignature(dspy.Signature):
    """Extract and structure information from user input."""
    user_input: str = dspy.InputField(desc="The user's input")
    conversation_context: str = dspy.InputField(desc="Recent conversation context")
    extracted_info: str = dspy.OutputField(desc="Key information extracted from user input")

class QuestionGeneratorSignature(dspy.Signature):
    """Generate relevant questions based on current information."""
    current_info: str = dspy.InputField(desc="Current information summary")
    conversation_context: str = dspy.InputField(desc="Recent conversation context")
    questions: str = dspy.OutputField(desc="3 relevant questions to ask next")
    category: str = dspy.OutputField(desc="Category these questions belong to")

class GapAnalysisSignature(dspy.Signature):
    """Analyze information gaps and provide feedback."""
    information_summary: str = dspy.InputField(desc="Current information summary")
    feedback: str = dspy.OutputField(desc="Analysis of information completeness and gaps")
    missing_areas: str = dspy.OutputField(desc="Areas that need more information")

class PlanGeneratorSignature(dspy.Signature):
    """Generate migration plan based on information and knowledge base."""
    information_summary: str = dspy.InputField(desc="Collected information summary")
    knowledge_base: str = dspy.InputField(desc="Relevant information from knowledge base")
    plan: str = dspy.OutputField(desc="Detailed migration plan")
    assumptions: str = dspy.OutputField(desc="Assumptions made in the plan")
    risks: str = dspy.OutputField(desc="Identified risks and gaps")

class ConversationManager(dspy.Module):
    """Simplified conversation manager for MVP demo."""
    
    def __init__(self, vector_search_endpoint, vector_index):
        super().__init__()
        self.storage = SimpleStorage()
        self.vector_search_endpoint = vector_search_endpoint
        self.vector_index = vector_index
        
        # Initialize DSPy components
        self.greeting_handler = dspy.ChainOfThought(GreetingSignature)
        self.info_collector = dspy.ChainOfThought(InformationCollectorSignature)
        self.question_generator = dspy.ChainOfThought(QuestionGeneratorSignature)
        self.gap_analyzer = dspy.ChainOfThought(GapAnalysisSignature)
        self.plan_generator = dspy.ChainOfThought(PlanGeneratorSignature)
        
        # Initialize vector search client
        self.vsc = VectorSearchClient()
    
    def process_user_input(self, user_input):
        """Main entry point for processing user input."""
        user_input_lower = user_input.lower().strip()
        
        # Flow 1: Greeting
        if any(greeting in user_input_lower for greeting in ["hi", "hello", "help", "what can you", "capabilities"]):
            return self._handle_greeting(user_input)
        
        # Flow 4: Plan generation
        elif "/plan" in user_input_lower or "generate plan" in user_input_lower or "create plan" in user_input_lower:
            return self._handle_plan_generation(user_input)
        
        # Flow 3: Feedback request
        elif any(feedback in user_input_lower for feedback in ["feedback", "how's it going", "progress", "status"]):
            return self._handle_feedback_request(user_input)
        
        # Flow 2: Information collection (default)
        else:
            return self._handle_information_collection(user_input)
    
    def _handle_greeting(self, user_input):
        """Handle greeting and capability explanation."""
        result = self.greeting_handler(user_input=str(user_input))
        response = result.response
        
        self.storage.add_conversation(user_input, response)
        return response
    
    def _handle_information_collection(self, user_input):
        """Handle information collection with 3 questions at a time."""
        # Extract information from user input
        context = self._get_conversation_context()
        extract_result = self.info_collector(
            user_input=str(user_input),
            conversation_context=str(context)
        )
        
        # Update summary with new information
        if extract_result.extracted_info.strip():
            self.storage.update_summary(extract_result.extracted_info)
        
        # Generate next 3 questions
        current_info = self.storage.get_summary()
        question_result = self.question_generator(
            current_info=str(current_info),
            conversation_context=str(context)
        )
        
        # Format response
        response = f"Thank you for that information. Let me ask you 3 more questions:\n\n"
        questions = question_result.questions.split('\n')[:3]  # Take first 3 questions
        for i, q in enumerate(questions, 1):
            if q.strip():
                response += f"{i}. {q.strip()}\n"
        
        response += f"\nPlease answer these questions, and I'll ask 3 more based on your responses."
        
        self.storage.add_conversation(user_input, response)
        return response
    
    def _handle_feedback_request(self, user_input):
        """Handle feedback on information collection progress."""
        current_info = self.storage.get_summary()
        context = self._get_conversation_context()
        
        gap_result = self.gap_analyzer(
            information_summary=str(current_info),
            feedback="Analyze completeness and identify gaps"
        )
        
        response = f"Based on what you've shared so far:\n\n"
        response += f"**Information Collected:**\n{current_info[:200]}...\n\n"
        response += f"**Analysis:** {gap_result.feedback}\n\n"
        response += f"**Missing Areas:** {gap_result.missing_areas}\n\n"
        response += f"Continue sharing information or type '/plan' when ready to generate your migration plan."
        
        self.storage.add_conversation(user_input, response)
        return response
    
    def _handle_plan_generation(self, user_input):
        """Handle plan generation with vector search."""
        current_info = self.storage.get_summary()
        
        # Search knowledge base
        knowledge_base = self._search_knowledge_base(current_info)
        
        # Generate plan
        plan_result = self.plan_generator(
            information_summary=str(current_info),
            knowledge_base=str(knowledge_base)
        )
        
        response = f"# Migration Plan Generated\n\n"
        response += f"## Plan Overview\n{plan_result.plan}\n\n"
        response += f"## Assumptions Made\n{plan_result.assumptions}\n\n"
        response += f"## Identified Risks\n{plan_result.risks}\n\n"
        response += f"*Plan generated based on your information and our knowledge base.*"
        
        self.storage.add_conversation(user_input, response)
        return response
    
    def _get_conversation_context(self):
        """Get recent conversation context."""
        return self.storage.get_conversation_context()
    
    def _search_knowledge_base(self, query):
        """Search vector index for relevant information."""
        try:
            search_results = self.vsc.get_index(
                endpoint_name=self.vector_search_endpoint,
                index_name=self.vector_index
            ).query(
                query_text=query,
                columns=["content", "title", "category", "source"],
                num_results=5
            )
            
            if search_results and 'result' in search_results and 'data_array' in search_results['result']:
                knowledge_items = []
                for item in search_results['result']['data_array']:
                    knowledge_items.append(f"**{item.get('title', 'Unknown')}**: {item.get('content', '')[:200]}...")
                return "\n".join(knowledge_items)
            else:
                return "No relevant knowledge base information found."
        except Exception as e:
            print(f"Vector search error: {e}")
            return "Knowledge base search unavailable."

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. Main Migration Planning Agent

# COMMAND ----------

class MigrationPlanningAgent(dspy.Module):
    """Main agent that orchestrates the migration planning process using modular architecture."""
    
    def __init__(self, vector_search_endpoint, vector_index, conversation_id=None):
        super().__init__()
        
        # Store conversation ID for persistent storage
        self.conversation_id = conversation_id
        
        # Create new memory storage instance for this conversation
        self.memory_storage = MemoryEnabledStorage(conversation_id=self.conversation_id)
        
        # Initialize modular agents with proper wiring for direct handoffs
        self.user_interaction_agent = UserInteractionAgent()
        self.question_generator_agent = QuestionGeneratorAgent()
        self.planner_agent = PlannerAgent()
        self.information_quality_agent = InformationQualityAgent(
            question_agent=self.question_generator_agent,
            planner_agent=self.planner_agent
        )
        self.information_collector_agent = InformationCollectorAgent(
            vector_search_endpoint, 
            vector_index,
            quality_agent=self.information_quality_agent,
            question_agent=self.question_generator_agent,
            conversation_id=self.conversation_id
        )
    
    def forward(self, user_input=None, **kwargs):
        """Main forward method for MLflow deployment using modular architecture."""
        print(f"üöÄ MigrationPlanningAgent: Starting main flow")
        print(f"   Input: '{str(user_input)[:50]}...'")
        
        # Get conversation state from memory-enabled storage
        conv_data = self.memory_storage.get_conversation_state()
        project_context = conv_data.get("project_context", "")
        conversation_stage = conv_data.get("conversation_stage", "initial")
        plan_generated = conv_data.get("plan_generated", False)
        
        # Handle different input formats from MLflow PyFunc
        if user_input is None:
            # If no positional argument, check kwargs
            if "user_input" in kwargs:
                user_input = kwargs["user_input"]
            elif "inputs" in kwargs:
                user_input = kwargs["inputs"]
            else:
                # Try to get the first value from kwargs
                user_input = next(iter(kwargs.values())) if kwargs else ""
        
        # Handle dictionary input format (MLflow signature format)
        if isinstance(user_input, dict):
            if "user_input" in user_input:
                user_input = user_input["user_input"]
            elif "inputs" in user_input:
                user_input = user_input["inputs"]
            else:
                # Handle other dictionary formats
                user_input = str(user_input)
        # Handle ChatCompletionRequest format (for agent compatibility)
        elif hasattr(user_input, 'messages') and len(user_input.messages) > 0 and hasattr(user_input.messages[0], 'content'):
            user_input = user_input.messages[0].content
        else:
            user_input = str(user_input).strip()
        
        # Handle special commands
        if user_input.lower() == "/plan":
            print("üìã MigrationPlanningAgent: Processing /plan command")
            return self._generate_plan()
        elif user_input.lower() == "/status":
            print("üìä MigrationPlanningAgent: Processing /status command")
            return self._get_status()
        elif user_input.lower() == "/help":
            print("‚ùì MigrationPlanningAgent: Processing /help command")
            return self._get_help()
        
        # Use User Interaction Agent to route the conversation following design flow
        print(f"üîÑ MigrationPlanningAgent: Calling UserInteractionAgent")
        interaction_result = self.user_interaction_agent(
            user_input, 
            project_context
        )
        
        # Handle direct responses from UserInteractionAgent (greeting)
        if isinstance(interaction_result, str):
            print(f"‚úÖ MigrationPlanningAgent: Received direct response from UserInteractionAgent")
            # Store conversation history in memory
            self.memory_storage.store_information(
                content=f"User: {user_input} | Agent: {interaction_result}",
                metadata={"type": "conversation_history", "timestamp": str(datetime.now())}
            )
            return interaction_result
        
        # Handle handoff signals for direct agent-to-agent handoffs
        elif isinstance(interaction_result, dict):
            action = interaction_result.get("action")
            print(f"üéØ MigrationPlanningAgent: Received handoff signal: {action}")
            
            if action == "collect_information":
                print(f"üìä MigrationPlanningAgent: Design Flow: UserInteractionAgent ‚Üí InformationCollectorAgent")
                
                # Update project context if this is initial input
                if interaction_result["intent"] == "project_context_provided":
                    self.memory_storage.update_conversation_state({
                        "project_context": user_input,
                        "conversation_stage": "collecting"
                    })
                    print(f"üìù MigrationPlanningAgent: Updated project context and conversation stage")
                
                # Direct handoff to InformationCollectorAgent
                print(f"üîÑ MigrationPlanningAgent: Handing off to InformationCollectorAgent")
                response = self.information_collector_agent.process_information(user_input, project_context, self.memory_storage)
                # Store conversation history in memory
                self.memory_storage.store_information(
                    content=f"User: {user_input} | Agent: {response}",
                    metadata={"type": "conversation_history", "timestamp": str(datetime.now())}
                )
                return response
                
            elif action == "generate_plan":
                print(f"üìã MigrationPlanningAgent: Design Flow: UserInteractionAgent ‚Üí PlannerAgent")
                
                if conversation_stage != "ready_for_plan" and not plan_generated:
                    print(f"‚ö†Ô∏è MigrationPlanningAgent: Insufficient information for plan generation")
                    return "I need to gather more information before generating a plan. Please answer a few more questions or use /status to see progress."
                
                # Get collected information and generate plan
                print(f"üîÑ MigrationPlanningAgent: Handing off to PlannerAgent")
                collection_result = self.information_collector_agent.collect_information("", project_context, self.memory_storage)
                response = self.planner_agent.generate_plan(collection_result.collected_data, collection_result.summary, collection_result.relevant_documents)
                # Store conversation history in memory
                self.memory_storage.store_information(
                    content=f"User: {user_input} | Agent: {response}",
                    metadata={"type": "conversation_history", "timestamp": str(datetime.now())}
                )
                return response
                
            else:
                print(f"‚ùì MigrationPlanningAgent: Unknown action from UserInteractionAgent: {action}")
                return "I'm not sure how to help with that. Could you please clarify what you need?"
        
        # Fallback for unexpected response format
        print(f"‚ö†Ô∏è MigrationPlanningAgent: Unexpected response format from UserInteractionAgent")
        return "I'm not sure how to help with that. Could you please clarify what you need?"
    
    def _handle_clarification(self, user_input):
        """Handle clarification requests."""
        return f"""**I'm not sure I understand what you're looking for.**

Could you please clarify:
- Are you planning a customer use case delivery (like a migration to Databricks)?
- Do you need help creating a delivery plan for a customer?
- Or do you have a different question about use case planning?

You can also use `/help` to see what I can assist you with."""
    
    
    def _generate_plan(self):
        """Generate migration plan using modular architecture."""
        print(f"üìã MigrationPlanningAgent: Starting plan generation process")
        
        # Get conversation state from memory
        conv_data = self.memory_storage.get_conversation_state()
        conversation_stage = conv_data.get("conversation_stage", "initial")
        plan_generated = conv_data.get("plan_generated", False)
        project_context = conv_data.get("project_context", "")
        
        if conversation_stage != "ready_for_plan" and not plan_generated:
            print(f"‚ö†Ô∏è MigrationPlanningAgent: Insufficient information for plan generation")
            return "I need to gather more information before generating a plan. Please answer a few more questions or use /status to see progress."
        
        # Get collected information
        print(f"üìä MigrationPlanningAgent: Getting collected information")
        collection_result = self.information_collector_agent.collect_information("", project_context)
        
        # Generate the plan using Planner Agent
        print(f"üîÑ MigrationPlanningAgent: Generating plan using PlannerAgent")
        plan_result = self.planner_agent.generate_plan(
            collection_result.collected_data,
            collection_result.summary,
            collection_result.relevant_documents
        )
        
        # Update conversation state in memory
        self.memory_storage.update_conversation_state({
            "plan_generated": "true",
            "conversation_stage": "planning_complete"
        })
        print(f"‚úÖ MigrationPlanningAgent: Plan generation completed successfully")
        
        # Format the plan with proper structure
        formatted_plan = f"""
# Migration Plan for: {project_context[:100]}...

## Project Overview
{plan_result.migration_plan}

## Migration Timeline
{plan_result.timeline}

## Resource Requirements
{plan_result.resource_requirements}

## Risk Assessment
{plan_result.risks}

---
**Plan Quality Metrics:**
- Quality Score: {plan_result.quality_score}/100
- Identified Gaps: {plan_result.gaps}
- Recommendations: {plan_result.recommendations}
"""
        
        return formatted_plan
    
    def _get_status(self):
        """Get current status using modular architecture."""
        print(f"üìä MigrationPlanningAgent: Generating status report")
        
        # Get conversation state from memory
        conv_data = self.memory_storage.get_conversation_state()
        project_context = conv_data.get("project_context", "")
        
        # Get information from Information Collector Agent
        print(f"üìä MigrationPlanningAgent: Getting collected information for status")
        collection_result = self.information_collector_agent.collect_information("", project_context)
        
        # Assess quality
        print(f"üîç MigrationPlanningAgent: Assessing information quality")
        quality_result = self.information_quality_agent.assess_quality(
            collection_result.collected_data,
            collection_result.summary
        )
        print(f"üìä MigrationPlanningAgent: Status - Progress: {quality_result.completeness_score:.0%}, Ready: {quality_result.ready_for_planning}")
        
        
        return f"""**Migration Planning Status**

**Progress:** {quality_result.completeness_score:.0%} complete
**Ready for Plan:** {'Yes' if quality_result.ready_for_planning else 'No'}

**What I know so far:**
{collection_result.summary[:150]}{'...' if len(collection_result.summary) > 150 else ''}

**Next Steps:**
- {'Ready to generate plan!' if quality_result.ready_for_planning else 'Provide more information to complete the assessment'}"""
    
    def _get_help(self):
        """Get help information."""
        return """**Use Case Delivery Planning Agent Help**

**Available Commands:**
- `/plan` - Generate your comprehensive delivery plan
- `/status` - View current progress and data gathered
- `/help` - Show this help information

**What I do:**
- Help Databricks account teams create delivery plans for customer use cases
- Generate mutual action plans that accelerate customer onboarding
- Adapt proven playbooks to customer-specific needs
- Embed Databricks best practices and delivery standards

**How it works:**
1. Tell me about your use case or migration project
2. I'll ask targeted questions to understand requirements
3. Use `/status` to see progress anytime
4. When ready, use `/plan` to generate your detailed delivery plan

**Current Focus:** Migration Planning (Oracle, SQL Server, Teradata to Databricks)

**Benefits:**
- 80-90% reduction in manual planning effort
- Consistent onboarding across teams
- Faster customer time-to-value

*Just answer the questions in each batch to continue planning your migration!*"""

print("Main MigrationPlanningAgent implemented successfully!")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Comprehensive Agent Testing

# COMMAND ----------

def comprehensive_agent_test():
    """Comprehensive test of the Migration Planning Agent with flow verification."""
    print("=" * 80)
    print("COMPREHENSIVE MIGRATION PLANNING AGENT TEST")
    print("Testing Agent Flow Against Design Specification")
    print("=" * 80)
    
    # Create a fresh agent instance with memory storage
    test_agent = MigrationPlanningAgent(
        vector_search_endpoint=vector_search_endpoint,
        vector_index=vector_index_name,
        conversation_id="test_comprehensive"
    )
    
    test_cases = [
        {
            "name": "Flow Test: Greeting ‚Üí GreetingHandler",
            "input": "Hello",
            "expected_contains": ["Hello", "Use Case Delivery Planning Agent", "Databricks"],
            "flow_check": "UserInteractionAgent ‚Üí GreetingHandler (Direct Response)"
        },
        {
            "name": "Flow Test: Project Context ‚Üí InformationCollector",
            "input": "I want to migrate a customer from Oracle Exadata to Databricks",
            "expected_contains": ["questions", "information", "plan"],
            "flow_check": "UserInteractionAgent ‚Üí InformationCollectorAgent ‚Üí InformationQualityAgent ‚Üí QuestionGeneratorAgent"
        },
        {
            "name": "Flow Test: Information Collection ‚Üí Quality Assessment",
            "input": "We have 10 DBAs and 20 Data Engineers in the central team. They are trained in Databricks and we are using Professional Services.",
            "expected_contains": ["questions", "information", "plan"],
            "flow_check": "InformationCollectorAgent ‚Üí InformationQualityAgent ‚Üí QuestionGeneratorAgent"
        },
        {
            "name": "Flow Test: More Information ‚Üí Quality Check",
            "input": "We have 50TB of data, need real-time analytics, and use ETL processes with batch processing. Our current architecture is quite mature.",
            "expected_contains": ["questions", "plan", "status"],
            "flow_check": "InformationCollectorAgent ‚Üí InformationQualityAgent ‚Üí Decision Point"
        },
        {
            "name": "Flow Test: Status Check (Direct)",
            "input": "/status",
            "expected_contains": ["Migration Planning Status", "Progress", "Ready for Plan"],
            "flow_check": "Direct Status Check (No Agent Flow)"
        },
        {
            "name": "Flow Test: Help Command (Direct)",
            "input": "/help",
            "expected_contains": ["Use Case Delivery Planning Agent Help", "Commands", "What I do"],
            "flow_check": "Direct Help Check (No Agent Flow)"
        }
    ]
    
    passed_tests = 0
    total_tests = len(test_cases)
    flow_verification = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. Testing: {test_case['name']}")
        print(f"   Input: {test_case['input']}")
        print(f"   Expected Flow: {test_case['flow_check']}")
        
        try:
            response = test_agent(test_case['input'])
            print(f"   Response Length: {len(str(response))} characters")
            
            # Check if response contains expected content
            response_str = str(response).lower()
            contains_expected = all(expected.lower() in response_str for expected in test_case['expected_contains'])
            
            if contains_expected:
                print(f"   ‚úÖ PASSED - Flow working correctly")
                passed_tests += 1
                flow_verification.append(f"‚úÖ {test_case['name']}: {test_case['flow_check']}")
            else:
                print(f"   ‚ùå FAILED - Missing expected content: {test_case['expected_contains']}")
                print(f"   Response preview: {str(response)[:200]}...")
                flow_verification.append(f"‚ùå {test_case['name']}: Flow issue detected")
                
        except Exception as e:
            print(f"   ‚ùå ERROR: {str(e)}")
            flow_verification.append(f"‚ùå {test_case['name']}: Error - {str(e)}")
    
    print("\n" + "=" * 80)
    print("FLOW VERIFICATION RESULTS")
    print("=" * 80)
    for verification in flow_verification:
        print(verification)
    
    print("\n" + "=" * 80)
    print(f"TEST RESULTS: {passed_tests}/{total_tests} tests passed")
    print(f"Success Rate: {(passed_tests/total_tests)*100:.1f}%")
    print("=" * 80)
    
    
    return passed_tests == total_tests

# Run comprehensive test
print("Starting comprehensive agent test...")
test_success = comprehensive_agent_test()

# COMMAND ----------

# MAGIC %md
# MAGIC ### Test Information Persistence

# COMMAND ----------

def test_information_persistence():
    """Test that information is properly stored and retrieved across multiple calls."""
    print("=" * 80)
    print("TESTING INFORMATION PERSISTENCE")
    print("=" * 80)
    
    # Create a fresh agent instance
    test_agent = MigrationPlanningAgent(
        vector_search_endpoint=vector_search_endpoint,
        vector_index=vector_index_name,
        conversation_id="test_persistence"
    )
    
    # Clear any existing test data (memory storage doesn't need explicit clearing)
    # Memory storage will handle this automatically
    
    print("\n1. First interaction - providing initial project context")
    response1 = test_agent("I want to migrate Oracle Exadata to Databricks")
    print(f"Response 1: {response1[:100]}...")
    
    # Check if information was stored
    conv_data = memory_storage.get_conversation_state()
    all_info = memory_storage.get_all_information()
    print(f"Stored project context: {conv_data.get('project_context', 'None')}")
    print(f"Collected data items: {len(all_info)}")
    
    print("\n2. Second interaction - providing more information")
    response2 = test_agent("We have 10 DBAs and 20 Data Engineers. They are trained in Databricks and we are using Professional Services.")
    print(f"Response 2: {response2[:100]}...")
    
    # Check if information was accumulated
    all_info = memory_storage.get_all_information()
    print(f"Updated collected data items: {len(all_info)}")
    print(f"Information stored: {len(all_info)} items")
    
    print("\n3. Third interaction - providing additional details")
    response3 = test_agent("We have 20TB of data, 100 schemas, and 1000 tables. Peak processing is during evenings.")
    print(f"Response 3: {response3[:100]}...")
    
    # Check final state
    all_info = memory_storage.get_all_information()
    print(f"Final collected data items: {len(all_info)}")
    print(f"Final information stored: {len(all_info)} items")
    
    print("\n4. Status check to verify information retention")
    status_response = test_agent("/status")
    print(f"Status response: {status_response[:200]}...")
    
    # Verify that the agent doesn't ask for the same information again
    print("\n5. Testing that agent doesn't repeat questions")
    response4 = test_agent("We need to complete migration within 1 year")
    print(f"Response 4: {response4[:100]}...")
    
    # Check if the response contains questions about information already provided
    if "Oracle Exadata" in response4 and "DBAs" in response4 and "Data Engineers" in response4:
        print("‚ùå FAILED: Agent is asking for information already provided")
        return False
    else:
        print("‚úÖ PASSED: Agent is not repeating questions about already provided information")
        return True

# Run persistence test
print("Testing information persistence...")
persistence_success = test_information_persistence()

# COMMAND ----------

# MAGIC %md
# MAGIC ### Test Conversation Storage

# COMMAND ----------

def test_conversation_storage():
    """Test the conversation storage mechanism directly."""
    print("=" * 60)
    print("TESTING CONVERSATION STORAGE")
    print("=" * 60)
    
    # Test basic storage operations
    test_id = "storage_test"
    
    # Clear any existing test data (memory storage handles this automatically)
    # No need to explicitly clear memory storage
    
    # Test getting conversation state
    conv_state = memory_storage.get_conversation_state()
    print(f"1. New conversation state: {conv_state['conversation_stage']}")
    
    # Test updating conversation state
    memory_storage.update_conversation_state({
        "project_context": "Oracle to Databricks migration",
        "conversation_stage": "collecting"
    })
    
    # Test storing information
    memory_storage.store_information("Test data for storage test", metadata={"test": "data"})
    
    # Test retrieving updated state
    updated_state = memory_storage.get_conversation_state()
    print(f"2. Updated conversation: {updated_state['project_context']}")
    print(f"   Stage: {updated_state['conversation_stage']}")
    
    # Test information retrieval
    all_info = memory_storage.get_all_information()
    print(f"3. Stored information items: {len(all_info)}")
    
    print("‚úÖ Conversation storage test completed successfully!")
    return True

# Run storage test
print("Testing conversation storage...")
storage_success = test_conversation_storage()

# COMMAND ----------

# MAGIC %md
# MAGIC ### Test Memory-Enabled Storage

# COMMAND ----------

def test_memory_enabled_storage():
    """Test the memory-enabled storage system."""
    print("=" * 60)
    print("TESTING MEMORY-ENABLED STORAGE")
    print("=" * 60)
    print("Using same Databricks model as DSPy: databricks/databricks-claude-sonnet-4")
    
    # Test basic memory operations
    print("1. Testing information storage...")
    success1 = memory_storage.store_information(
        "Oracle Exadata migration project with 20TB data",
        metadata={"type": "project_info", "size": "20TB"}
    )
    print(f"   Storage result: {'‚úÖ Success' if success1 else '‚ùå Failed'}")
    
    print("2. Testing information retrieval...")
    all_info = memory_storage.get_all_information()
    print(f"   Retrieved {len(all_info)} information items")
    
    print("3. Testing semantic search...")
    search_results = memory_storage.search_information("Oracle migration", limit=3)
    print(f"   Found {len(search_results)} relevant results")
    
    print("4. Testing conversation state...")
    state = memory_storage.get_conversation_state()
    print(f"   Current state: {state}")
    
    print("5. Testing state updates...")
    memory_storage.update_conversation_state({
        "project_context": "Oracle to Databricks migration",
        "conversation_stage": "collecting"
    })
    updated_state = memory_storage.get_conversation_state()
    print(f"   Updated state: {updated_state}")
    
    print("‚úÖ Memory-enabled storage test completed successfully!")
    return True

# Run memory storage test
print("Testing memory-enabled storage...")
memory_success = test_memory_enabled_storage()


# COMMAND ----------

# MAGIC %md
# MAGIC ## 8. DSPy Model Compilation

# COMMAND ----------

# Create the simplified MVP agent
mvp_agent = ConversationManager(
    vector_search_endpoint=vector_search_endpoint,
    vector_index=vector_index_name
)

# Keep the original agent for comparison
migration_agent = MigrationPlanningAgent(
    vector_search_endpoint=vector_search_endpoint,
    vector_index=vector_index_name,
    conversation_id="default"  # Use default conversation ID for memory persistence
)

# COMMAND ----------

# MAGIC %md
# MAGIC ### Compile the DSPy Model
# MAGIC
# MAGIC Following the MLflow DSPy documentation, we need to compile our DSPy model using an optimizer to improve its performance before logging to MLflow.

# COMMAND ----------

# SKIP DSPy COMPILATION - Use the agent as-is
# The current agent architecture is already well-designed and doesn't need compilation
# DSPy compilation is more beneficial for simple signature-based modules, not complex multi-agent systems

print("Skipping DSPy compilation - using the agent as-is")
print("The modular agent architecture is already optimized and doesn't benefit from compilation")

# COMMAND ----------

# Use the agent directly without compilation
# The modular architecture is already well-designed and optimized
compiled_migration_agent = migration_agent
print("Using the agent directly without compilation")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Create ResponsesAgent Wrapper for Databricks Agent Framework

# COMMAND ----------

from uuid import uuid4
from mlflow.pyfunc import ResponsesAgent
from mlflow.types.responses import (
    ResponsesAgentRequest,
    ResponsesAgentResponse,
    ResponsesAgentStreamEvent,
)

class MigrationPlanningResponsesAgent(ResponsesAgent):
    """ResponsesAgent wrapper for Databricks Agent Framework compatibility."""
    
    def __init__(self, dspy_agent):
        super().__init__()
        self.agent = dspy_agent
        # Configure DSPy LM for the agent
        self._configure_dspy_lm()
    
    def _configure_dspy_lm(self):
        """Configure DSPy language model for the agent."""
        try:
            # Check if DSPy is already configured
            if hasattr(dspy.settings, 'lm') and dspy.settings.lm is not None:
                print("DSPy LM already configured, skipping configuration.")
                return
            
            # Configure DSPy with the same LM used during training
            lm = dspy.LM(model="databricks/databricks-claude-sonnet-4")
            dspy.settings.configure(lm=lm)
            print("DSPy LM configured successfully with databricks/databricks-claude-sonnet-4.")
        except Exception as e:
            print(f"Warning: Could not configure DSPy LM: {e}")
            # Try alternative configuration
            try:
                dspy.settings.configure(lm=dspy.LM("databricks/databricks-claude-sonnet-4"))
                print("DSPy LM configured with alternative method using databricks/databricks-claude-sonnet-4.")
            except Exception as e2:
                print(f"Warning: Alternative DSPy LM configuration also failed: {e2}")
                print("The agent may not work properly without LM configuration.")
    
    def _ensure_dspy_lm_configured(self):
        """Ensure DSPy LM is configured before prediction."""
        try:
            if not hasattr(dspy.settings, 'lm') or dspy.settings.lm is None:
                self._configure_dspy_lm()
        except Exception as e:
            print(f"Warning: Could not ensure DSPy LM configuration: {e}")
    
    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:
        """Non-streaming prediction."""
        # Ensure DSPy LM is configured
        self._ensure_dspy_lm_configured()
        
        # Extract user input from the request
        user_input = self._extract_user_input(request)
        
        # Call the DSPy agent (use module() instead of module.forward())
        response = self.agent(user_input)
        
        # Convert to ResponsesAgent format
        output_item = self.create_text_output_item(
            text=str(response), 
            id=str(uuid4())
        )
        
        return ResponsesAgentResponse(output=[output_item])
    
    def predict_stream(self, request: ResponsesAgentRequest):
        """Simple streaming - returns single response as stream."""
        # Get the response from regular predict
        response = self.predict(request)
        
        # Return as single stream event (no actual streaming)
        yield ResponsesAgentStreamEvent(
            type="response.output_item.done",
            item=response.output[0]
        )
    
    def _extract_user_input(self, request: ResponsesAgentRequest) -> str:
        """Extract user input from ResponsesAgentRequest."""
        if request.input and len(request.input) > 0:
            # Get the last user message
            for message in reversed(request.input):
                if message.role == "user" and message.content:
                    # Extract text from content
                    if isinstance(message.content, list):
                        # Handle content as list of content items
                        text_parts = []
                        for content_item in message.content:
                            if hasattr(content_item, 'text'):
                                text_parts.append(content_item.text)
                            elif isinstance(content_item, str):
                                text_parts.append(content_item)
                        return " ".join(text_parts)
                    elif isinstance(message.content, str):
                        return message.content
                    else:
                        return str(message.content)
        
        return "Hello, I need help with migration planning."

# Create the ResponsesAgent wrapper using MVP agent
responses_agent = MigrationPlanningResponsesAgent(mvp_agent)
print("ResponsesAgent wrapper created successfully with MVP agent!")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Test MVP Agent Flows
# MAGIC 
# MAGIC Test the 4 user flows with the simplified MVP agent

# COMMAND ----------

# Test Flow 1: Greeting
print("=== Testing Flow 1: Greeting ===")
test_input_1 = "Hi, what can you help with?"
response_1 = mvp_agent.process_user_input(test_input_1)
print(f"User: {test_input_1}")
print(f"Agent: {response_1}")
print()

# COMMAND ----------

# Test Flow 2: Information Collection
print("=== Testing Flow 2: Information Collection ===")
test_input_2 = "I want to migrate from Snowflake to Databricks"
response_2 = mvp_agent.process_user_input(test_input_2)
print(f"User: {test_input_2}")
print(f"Agent: {response_2}")
print()

# COMMAND ----------

# Test Flow 3: Feedback Request
print("=== Testing Flow 3: Feedback Request ===")
test_input_3 = "How's the information collection going?"
response_3 = mvp_agent.process_user_input(test_input_3)
print(f"User: {test_input_3}")
print(f"Agent: {response_3}")
print()

# COMMAND ----------

# Test Flow 4: Plan Generation
print("=== Testing Flow 4: Plan Generation ===")
test_input_4 = "/plan"
response_4 = mvp_agent.process_user_input(test_input_4)
print(f"User: {test_input_4}")
print(f"Agent: {response_4}")
print()

# COMMAND ----------

# MAGIC %md
# MAGIC ## 9. MLflow Model Registration

# COMMAND ----------

# Input example for the model - plain string as per MLflow DSPy documentation
input_example = "I need to migrate our Oracle data warehouse to Databricks"


# Use native MLflow DSPy logging with proper agent signatures
from mlflow.models import ModelSignature
from mlflow.types import ColSpec
from mlflow.types.llm import ChatCompletionRequest, ChatMessage

# Disable MLflow autologging to avoid Pydantic serialization warnings
mlflow.autolog(disable=True)

# # Suppress Pydantic serialization warnings
# import warnings
# warnings.filterwarnings("ignore", message=".*PydanticSerializationUnexpectedValue.*")
# warnings.filterwarnings("ignore", message=".*Expected.*fields.*but got.*")


# Set the experiment for this run
mlflow.set_experiment(mlflow_experiment_name)

# Log the ResponsesAgent using MLflow (Databricks Agent Framework compatible)
with mlflow.start_run() as run:
    # Log the ResponsesAgent - this automatically handles the correct schema for Agent Framework
    model_info = mlflow.pyfunc.log_model(
        python_model=responses_agent,
        name="usecase-planning-agent",
        input_example={
            "input": [
                {
                    "role": "user", 
                    "content": "I need to migrate our Oracle data warehouse to Databricks"
                }
            ]
        }
    )
    
    print(f"MigrationPlanningAgent V2 (ResponsesAgent) logged to MLflow: {model_info.model_uri}")
    print(f"Run ID: {run.info.run_id}")

# Register the model in Unity Catalog
catalog_name = "vbdemos"
schema_name = "usecase_agent"
model_name = f"{catalog_name}.{schema_name}.usecase-planning-agent"
uc_model_info = mlflow.register_model(model_uri=model_info.model_uri, name=model_name)

print(f"Model registered in Unity Catalog: {uc_model_info.name}")
print(f"   Version: {uc_model_info.version}")
print(f"Model ready for deployment!")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Test Registered Model
# MAGIC 
# MAGIC Test the registered model with different inputs

# COMMAND ----------

# Test the registered model with different inputs
test_inputs = [
    "Hi, what can you help with?",
    "I want to migrate from Snowflake to Databricks",
    "How's the information collection going?",
    "/plan"
]

print("=== Testing Registered Model ===")
for i, test_input in enumerate(test_inputs, 1):
    print(f"\n--- Test {i}: {test_input} ---")
    try:
        # Test the model directly
        result = responses_agent.predict(test_input)
        print(f"Response: {result['response'][:200]}...")
    except Exception as e:
        print(f"Error: {e}")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Test Streaming Support

# COMMAND ----------


# COMMAND ----------

# MAGIC %md
# MAGIC ### Test Question Flow Fix

# COMMAND ----------


# COMMAND ----------



# COMMAND ----------



# COMMAND ----------

# MAGIC %md
# MAGIC ## 10. Deploy Agent to Model Serving

# COMMAND ----------

# Import required libraries for deployment
from databricks import agents
import mlflow

# Check MLflow version compatibility
print(f"MLflow version: {mlflow.__version__}")
mlflow_version = mlflow.__version__
if mlflow_version < "2.20.0":
    print(f"WARNING: MLflow version {mlflow_version} is below 2.20.0")
    print("Agent Framework requires MLflow 2.20.0 or above for proper agent signatures.")
    print("Consider upgrading MLflow or the deployment may fail.")
else:
    print("MLflow version is compatible with Agent Framework.")

# COMMAND ----------

# Deploy the agent to Model Serving
print("Deploying agent to Model Serving...")
print(f"Model Name: {uc_model_info.name}")
print(f"Model Version: {uc_model_info.version}")

# List existing deployments for troubleshooting
try:
    print("\nChecking existing deployments...")
    existing_deployments = agents.list_deployments()
    if existing_deployments:
        print("Existing deployments found:")
        for dep in existing_deployments:
            print(f"  - {dep.name} (version {dep.version})")
    else:
        print("No existing deployments found.")
except Exception as e:
    print(f"Could not list existing deployments: {e}")

# Deploy the agent using the Agent Framework
# Use a static endpoint name to update the same endpoint
endpoint_name = "migration-planning-agent"
print(f"\nDeploying to endpoint: {endpoint_name}")

try:
    deployment = agents.deploy(uc_model_info.name, uc_model_info.version, endpoint_name=endpoint_name)
    print(f"Agent deployed successfully to endpoint: {endpoint_name}")
except Exception as e:
    print(f"Deployment to endpoint failed: {e}")
    print("Trying to clean up existing deployments and retry...")
    
    try:
        # Try to delete existing deployments for this model
        print("Attempting to clean up existing deployments...")
        # Note: This might fail if there are no existing deployments, which is fine
        agents.delete_deployment(uc_model_info.name, uc_model_info.version)
        print("Existing deployments cleaned up.")
        
        # Retry deployment
        deployment = agents.deploy(uc_model_info.name, uc_model_info.version, endpoint_name=endpoint_name)
        print(f"Agent deployed successfully after cleanup!")
    except Exception as e2:
        print(f"Cleanup and retry failed: {e2}")
        print("Please manually clean up incompatible model versions from the endpoint")
        print("or use a different endpoint name for deployment.")
        raise e2

# Retrieve the query endpoint URL for making API requests
print(f"Deployment successful!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 11. Summary

# COMMAND ----------

print("Migration Planning Agent V2 - Complete!")
print("=" * 60)
print(f"Model registered: {uc_model_info.name}")
print(f"Model version: {uc_model_info.version}")
print(f"Agent deployed to endpoint: migration-planning-agent")
print(f"Query endpoint: {deployment.query_endpoint}")
print(f"Deployment ID: {deployment.deployment_id}")
print("\nNext Steps:")
print("1. Test the agent via the Review App in Databricks UI")
print("2. Monitor agent performance using inference tables")
print("3. Provide feedback using the feedback API")
print("4. Scale the endpoint as needed for production traffic")
print("\nUseful Links:")
print(f"- Model in Unity Catalog: {uc_model_info.name}")
print(f"- Query Endpoint: {deployment.query_endpoint}")
print("- Review App: Available in Databricks UI under Model Serving")
print("- Inference Tables: Monitor logs and performance")
print("\nNote: Agent will update the same endpoint 'migration-planning-agent' on future deployments")